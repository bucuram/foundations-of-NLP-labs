{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPk3KLZX0X/KX9efdHgtQEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bucuram/foundations-of-NLP-labs/blob/main/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXkuh5_mj3Wx"
      },
      "source": [
        "##Word2vec\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pJqjzaGlQnT"
      },
      "source": [
        "Word representation methods from the last lab\n",
        "\n",
        "- Bag of Words\n",
        "- TF-IDF\n",
        "\n",
        "Limitations of these representations\n",
        "\n",
        "- High-dimensional\n",
        "- Sparse\n",
        "- No info about words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GPodGvnlyZX"
      },
      "source": [
        "Word2vec Paper [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkQ87w_smCcg"
      },
      "source": [
        "Word2Vec is a shallow, two-layer neural network which is trained to reconstruct linguistic contexts of words.\n",
        "\n",
        "It takes as its input a large corpus of words and produces a vector space, with each unique word in the corpus being assigned a corresponding vector in the space.\n",
        "\n",
        "\n",
        "Word vectors are positioned in the vector space such that words that share common contexts in the corpus are located in close proximity to one another in the space.\n",
        "\n",
        "Example:    \n",
        "The **kid** studies mathematics.\n",
        "\n",
        "The **child** studies mathematics.\n",
        "\n",
        "![embedding](https://miro.medium.com/max/1400/1*sAJdxEsDjsPMioHyzlN3_A.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7oue8cDnY1_"
      },
      "source": [
        "###Methods for building the Word2vec model\n",
        "\n",
        "![cbow-skip-gram](https://miro.medium.com/max/1400/1*cuOmGT7NevP9oJFJfVpRKA.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KUil7cBnY4u"
      },
      "source": [
        "###Continuous Bag-of-Words (CBOW)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb12NPvv3Zww"
      },
      "source": [
        "CBOW predicts target words from the surrounding context words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfz-eLcNnY7f"
      },
      "source": [
        "![cbow](https://1.bp.blogspot.com/-nZFc7P6o3Yc/XQo2cYPM_ZI/AAAAAAAABxM/XBqYSa06oyQ_sxQzPcgnUxb5msRwDrJrQCLcBGAs/s1600/image001.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZpZNbVynY91"
      },
      "source": [
        "###Skip-gram\n",
        "\n",
        "Skip-gram predicts surrounding context words from the target words.\n",
        "\n",
        "![skip-gram](https://i.stack.imgur.com/fYhXF.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38GGcsuG3s9_"
      },
      "source": [
        "##Architecture\n",
        "\n",
        "The words are feeded as one-hot vectors ( vector of the same length as the vocabulary, filled with zeros except at the index that represents the word we want to represent, which is assigned “1”.)\n",
        "\n",
        "The hidden layer is a standard fully-connected (Dense) layer whose weights are the word embeddings.\n",
        "\n",
        "The output layer outputs probabilities for the target words from the vocabulary.\n",
        "\n",
        "The goal of this neural network is to learn the weights for the hidden layer matrix.\n",
        "\n",
        "![model](https://miro.medium.com/max/1400/1*tmyks7pjdwxODh5-gL3FHQ.png)\n",
        "\n",
        "High-level illustration of the architecture\n",
        "\n",
        "![model2](https://i.imgur.com/CBuZay5.png)\n",
        "\n",
        "The rows of the hidden layer weight matrix, are actually the word vectors (word embeddings).\n",
        "\n",
        "\n",
        "![hidden-layer](https://i.imgur.com/v6VqHad.png)\n",
        "\n",
        "The hidden layer operates as a lookup table. The output of the hidden layer is just the “word vector” for the input word.\n",
        "\n",
        "More concretely, if you multiply a 1 x 10,000 one-hot vector by a 10,000 x 300 matrix, it will effectively just select the matrix row corresponding to the ‘1’.\n",
        "\n",
        "![vector](https://i.imgur.com/EYhcA5S.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqCMFRaI6S2a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZgTsN3Pmye0"
      },
      "source": [
        "###Semantic and syntactic relationships\n",
        "\n",
        "If different words are similar in context, then Word2Vec should have similar outputs when these words are passed as inputs, and in-order to have a similar outputs, the computed word vectors (in the hidden layer) for these words have to be similar, thus Word2Vec is motivated to learn similar word vectors for words in similar context.\n",
        "\n",
        "Word2Vec is able to capture multiple different degrees of similarity between words, such that semantic and syntactic patterns can be reproduced using vector arithmetic.\n",
        "\n",
        "![w2vec](https://i.imgur.com/I66L7No.png)\n",
        "\n",
        "![w2vec2](https://israelg99.github.io/images/2017-03-23-Word2Vec-Explained/linear-relationships.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Now1mZyS_dYe"
      },
      "source": [
        "**Skip-gram** - works well with a small amount of the training data, represents well even rare words or phrases\n",
        "\n",
        "**CBOW** - several times faster to train than the skip-gram, slightly better accuracy for the frequent words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSzy26Qw_dc5"
      },
      "source": [
        "###Word2vec embeddings in Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuFIQwiLQkB5"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BUnYjhKAWoI"
      },
      "source": [
        "Gensim has multiple vector representations for words: word2vec, fasttext, glove"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7rV7zCyAHdJ",
        "outputId": "48b1c1c3-488a-47b9-90c0-d051b6194dc8"
      },
      "source": [
        "print(list(gensim.downloader.info()['models'].keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo0dnaGaAesc"
      },
      "source": [
        "Downloading the word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XBIE2c_Aifx",
        "outputId": "65964be9-c576-4240-8a70-f5ea7cd98718"
      },
      "source": [
        "word2vec = gensim.downloader.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acjBn5fQRoxb",
        "outputId": "bb0f1718-b683-4903-9e62-4207d2574df3"
      },
      "source": [
        "word2vec['cat'][:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.0123291 ,  0.20410156, -0.28515625,  0.21679688,  0.11816406,\n",
              "        0.08300781,  0.04980469, -0.00952148,  0.22070312, -0.12597656,\n",
              "        0.08056641, -0.5859375 , -0.00445557, -0.296875  , -0.01312256,\n",
              "       -0.08349609,  0.05053711,  0.15136719, -0.44921875, -0.0135498 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6-ySA4OBK3P",
        "outputId": "fd6da804-0bc7-436c-c21e-9f73f82032d2"
      },
      "source": [
        "word2vec.similarity('dog', 'house')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25689757"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDMjYXayBNB1",
        "outputId": "61cb7dc1-08bf-4dc7-f22d-8aa59dffba93"
      },
      "source": [
        "word2vec.similarity('dog', 'puppy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81064284"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYtBf4mfBPsj",
        "outputId": "ed5c2cef-46d8-4265-fdd7-4fd75ff7154b"
      },
      "source": [
        "word2vec.most_similar('cat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cats', 0.8099379539489746),\n",
              " ('dog', 0.7609456777572632),\n",
              " ('kitten', 0.7464985251426697),\n",
              " ('feline', 0.7326233983039856),\n",
              " ('beagle', 0.7150583267211914),\n",
              " ('puppy', 0.7075453996658325),\n",
              " ('pup', 0.6934291124343872),\n",
              " ('pet', 0.6891531348228455),\n",
              " ('felines', 0.6755931377410889),\n",
              " ('chihuahua', 0.6709762215614319)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xixp7uGyEMTH"
      },
      "source": [
        "\n",
        "(king - man) + woman = queen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sms3zhUKBRVH",
        "outputId": "d376d2be-86ea-4a5e-faa2-5237ac688a04"
      },
      "source": [
        "word2vec.most_similar(positive=['woman', 'king'], negative=['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118192911148071),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321243286133),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('Queen_Consort', 0.5235945582389832),\n",
              " ('queens', 0.518113374710083),\n",
              " ('sultan', 0.5098593235015869),\n",
              " ('monarchy', 0.5087411999702454)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jogN9NS1VSHg",
        "outputId": "a4f8c6a5-bd6a-44dc-8656-bf7531e268d5"
      },
      "source": [
        "word2vec.most_similar(['woman', 'officer'], negative = ['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Officer', 0.5694271326065063),\n",
              " ('officers', 0.538264274597168),\n",
              " ('offi_cer', 0.5283650159835815),\n",
              " ('chief', 0.48523107171058655),\n",
              " ('deputy', 0.47100305557250977),\n",
              " ('patrolwoman', 0.4685642719268799),\n",
              " ('policewoman', 0.46202757954597473),\n",
              " ('vice_president', 0.461116224527359),\n",
              " ('supervisor', 0.4552857577800751),\n",
              " ('oficer', 0.4532422721385956)]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIs9pHp3BZTT"
      },
      "source": [
        "##Assignment\n",
        "\n",
        "To be uploaded here: https://forms.gle/KuR71xiA2rR6tukz8 until December 15th.\n",
        "\n",
        "1. Play around with the word2vec model and see if there are any interesting or counterintuitive similarity results using  ```word2vec.similarity``` and ```word2vec.most_similar```.\n",
        "\n",
        "2. Use other embeddings (glove, fasttext) to encode the data from the sentiment analysis task and train the classification model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "954luqj1ai_r"
      },
      "source": [
        "Using the word2vec embeddings from Gensim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAXlt86TUCWc",
        "outputId": "e50e4da1-3fad-4267-ef6f-e82de19f30c2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('twitter_samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kEMTQSnUwis",
        "outputId": "689af66a-d46e-49d4-c3cf-6bf1d681bf36"
      },
      "source": [
        "from nltk.corpus  import twitter_samples\n",
        "\n",
        "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "print(len(pos_tweets))\n",
        "\n",
        "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "print(len(neg_tweets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n",
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jLZO6yXUy7T"
      },
      "source": [
        "import pandas as pd\n",
        "pos_df = pd.DataFrame(pos_tweets, columns = ['tweet'])\n",
        "pos_df['label'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDhKlXNU0Hk"
      },
      "source": [
        "neg_df = pd.DataFrame(neg_tweets, columns = ['tweet'])\n",
        "neg_df['label'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgQua4ukU1Jl"
      },
      "source": [
        "data_df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
        "# data_df = data_df[:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGKhcf-QU3Gy",
        "outputId": "a1cf4ad1-fd6e-44c5-be9e-e57cf22d49b9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.2, shuffle = True)\n",
        "print(train_df)\n",
        "print(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  tweet  label\n",
            "6683  Why is \"27 and unmarried\" floating around my T...      0\n",
            "481   @min0rthreat_ hope everything is going great!!...      1\n",
            "9009     :( but wtf am I supposed to do now without her      0\n",
            "7333           @Ch4rm41n3 aww damn :( and haha will do!      0\n",
            "9060  @lucyanne_l Thank you for sending premium writ...      0\n",
            "...                                                 ...    ...\n",
            "8373           @solodmssunshine thats me omg imsorry :(      0\n",
            "5324  #DomesticViolence :( Proposed New Law Will Hel...      0\n",
            "6209  Still haven't decided how I want my name on my...      0\n",
            "3828  Randomly just booked tickets to go #Buckingham...      1\n",
            "6081                 @eleena_pv @apuchades I'm sorry :(      0\n",
            "\n",
            "[8000 rows x 2 columns]\n",
            "                                                  tweet  label\n",
            "9184                          @cessyybells sorry pre :(      0\n",
            "1762                                      Going Home :)      1\n",
            "726   @LeeCash Glad to hear that's back! If you see ...      1\n",
            "5220               i miss watching anna akana videos :(      0\n",
            "688                       @KidXSA Follow back please :)      1\n",
            "...                                                 ...    ...\n",
            "6263          Is it September yet? I need OUAT back :((      0\n",
            "2812  @lovingjeonboram :) Lets take it lighter down,...      1\n",
            "4147  @ppritam009 ABP NEWS ka article read kiya? :D ...      1\n",
            "7470       @tooshiin but dat was fun while it lasted :(      0\n",
            "208   @justinbieber can you please follow me @caitec...      1\n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UdnpkcGXmZv"
      },
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "def compute_embeddings(df):\n",
        "    train_emb = []\n",
        "    for i, row in tqdm.tqdm(df.iterrows(), total = len(df.index)):\n",
        "        words = row['tweet'].split(' ')\n",
        "        words = filter(lambda x: x in word2vec.vocab, words)\n",
        "        text_emb = [word2vec[word] for word in words]\n",
        "        \n",
        "        if len(text_emb) == 0:\n",
        "            train_emb.append(np.zeros(300))\n",
        "            continue\n",
        "\n",
        "        doc_embedding = np.mean(text_emb, axis = 0)\n",
        "        train_emb.append(doc_embedding)\n",
        "    return np.array(train_emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o65sQbtMS66a",
        "outputId": "ff78a5bf-0aae-44f9-ca1c-7d51506382be"
      },
      "source": [
        "X_train_emb = compute_embeddings(train_df)\n",
        "y_train = train_df['label']\n",
        "\n",
        "X_test_emb = compute_embeddings(test_df)\n",
        "y_test = test_df['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8000/8000 [00:01<00:00, 5950.31it/s]\n",
            "100%|██████████| 2000/2000 [00:00<00:00, 5797.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcflA2mDU79N",
        "outputId": "4908de41-430f-4d74-f712-60ffc7ca50f8"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(verbose = 2)\n",
        "svm.fit(X_train_emb, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7o_5xGfYJxG",
        "outputId": "ad0e521d-1e5b-45aa-e96e-19f5261d9011"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score \n",
        "\n",
        "y_test_pred = svm.predict(X_test_emb)\n",
        "\n",
        "print('Accuracy', accuracy_score(y_test, y_test_pred))\n",
        "print('Precision',precision_score(y_test, y_test_pred))\n",
        "print('F1 score',f1_score(y_test, y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.884\n",
            "Precision 0.9558282208588957\n",
            "F1 score 0.870391061452514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftFqAxWFlT_J"
      },
      "source": [
        "Notebook adapted from https://israelg99.github.io/2017-03-23-Word2Vec-Explained/\n",
        "\n",
        "Further Reading\n",
        "\n",
        "- [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/pdf/1607.06520.pdf)\n",
        "- [Debiaswe: try to make word embeddings less sexist](https://github.com/tolga-b/debiaswe)\n",
        "- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)\n",
        "- [Fasttext Word vectors for 157 languages](https://fasttext.cc/docs/en/crawl-vectors.html)\n",
        "- [Illustrated Word2vec](https://jalammar.github.io/illustrated-word2vec/)"
      ]
    }
  ]
}